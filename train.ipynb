{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS5228 Rental Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# load data\n",
    "train_data = pd.read_csv('./data/processed/train.csv')\n",
    "test_data = pd.read_csv('./data/processed/test.csv')\n",
    "\n",
    "X_train, y_train = train_data.drop(columns='monthly_rent'), train_data['monthly_rent'].copy()\n",
    "X_test = test_data\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression...\n",
      "Linear Regression training completed.\n",
      "Linear Regression training result saved.\n",
      "\n",
      "Training Elastic Net...\n",
      "Elastic Net training completed.\n",
      "Elastic Net training result saved.\n",
      "\n",
      "Training Gradient Boosting...\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1      428402.0293       59344.6650           40.98s\n",
      "         2      383360.6869       37570.2770           39.54s\n",
      "         3      352093.8604       34212.2632           35.98s\n",
      "         4      326951.2757       19487.4451           34.83s\n",
      "         5      309183.6291       19326.6161           33.93s\n",
      "         6      296014.6186       19883.6203           33.32s\n",
      "         7      284161.5803        9762.3773           32.89s\n",
      "         8      272746.9503        -183.0310           32.48s\n",
      "         9      269125.7007       20152.9672           32.28s\n",
      "        10      260476.4373       -5226.8048           31.99s\n",
      "        20      237276.9671       -7087.7901           29.15s\n",
      "        30      230414.8150       -2772.9943           26.95s\n",
      "        40      229023.6092        3090.9730           25.20s\n",
      "        50      224269.1480       -7053.2239           23.81s\n",
      "        60      223766.1992       -1368.2422           22.62s\n",
      "        70      222878.0632       -7301.8152           21.59s\n",
      "        80      223003.8499         -93.2495           20.54s\n",
      "        90      219292.0412        -241.7513           19.52s\n",
      "       100      220584.9460        3855.3026           18.52s\n",
      "       200      211484.3627       -1280.9629            9.11s\n",
      "       300      205932.1125        6462.7361            0.00s\n",
      "Gradient Boosting training completed.\n",
      "Gradient Boosting training result saved.\n",
      "\n",
      "Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest training completed.\n",
      "Random Forest training result saved.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    9.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Elastic Net': ElasticNet(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42, verbose=1),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42, verbose=1, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42, verbose=1, n_estimators=300, max_depth=4, learning_rate=0.15, subsample=0.8, max_features=0.8),\n",
    "    # 'SVM': SVR(),\n",
    "}\n",
    "\n",
    "# train models and save results\n",
    "for name, model in models.items():\n",
    "    print(f'Training {name}...')\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'{name} training completed.')\n",
    "\n",
    "    # Create a dataframe with two columns: Id & Predicted\n",
    "    result_df = pd.DataFrame({\n",
    "        'Id': range(len(y_pred)),\n",
    "        'Predicted': y_pred\n",
    "    })\n",
    "    save_path = './data/predictions/' + name + '.csv'\n",
    "    result_df.to_csv(save_path, index=False)\n",
    "    print(f'{name} training result saved.\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS5228",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
